{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615fd34d",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Prefce</font>\n",
    "Here we are going to use a toy testing environment `GridWorld` to demonstrate the usage of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd68f300",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Importing Packages</font>\n",
    "Firstly, let's import all the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce17785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline import lab\n",
    "from skyline.lab import gridworld_env\n",
    "from skyline.lab import gridworld_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797ee9",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Make Lab Environment</font>\n",
    "We can list supported environment as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54106b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GridWorld =====\n",
      "This is a environment to show case of Skyline lab. The environment is a grid world where you can move up, down, right and leftif you don't encounter obstacle. When you obtain the reward (-1, 1, 2), the game is over. You can use env.info() to learn more.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.list_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02fb4b",
   "metadata": {},
   "source": [
    "Then We use function <font color='blue'>make</font> to obtain the desired environment. e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff46a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_env = lab.make(lab.Env.GridWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33754c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- environment is a grid world\n",
      "- x means you can't go there\n",
      "- s means start position\n",
      "- number means reward at that state\n",
      "===========\n",
      ".  .  .  1\n",
      ".  x  . -1\n",
      ".  .  .  x\n",
      "s  x  .  2\n",
      "===========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what our environment looks like:\n",
    "grid_env.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7b6952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U', 'D', 'L', 'R']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show available actions\n",
    "grid_env.available_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2097e787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=3, j=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1564b",
   "metadata": {},
   "source": [
    "Let's take a action and check the state change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39fdf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=2, j=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take action 'Up'\n",
    "grid_env.step('U')\n",
    "\n",
    "# Check current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6748196",
   "metadata": {},
   "source": [
    "After taking action `U`, we expect the axis-i to move up from 2->1 and we can confirm it from the output state. Let's reset the environment by calling method <font color='blue'>reset</font> which will bring the state of environment back to intial state `GridState(i=2, j=0)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718ed1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=3, j=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset environment\n",
    "grid_env.reset()\n",
    "\n",
    "# Check current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd1109",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Experiments of RL algorithms</font>\n",
    "Here we are going to test some well-known RL algorithms and demonstrate the usage of this lab:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4293e",
   "metadata": {},
   "source": [
    "<a id='monte_carlo_method'></a>\n",
    "### <font color='darkgreen'>Monte Carlo Method</font>\n",
    "<b><font size='3ptx'>In this method, we simply simulate many trajectories (<font color='darkbrown'>decision processes</font>), and calculate the average returns.</font></b> ([wiki page](https://en.wikiversity.org/wiki/Reinforcement_Learning#Monte_Carlo_policy_evaluation))\n",
    "\n",
    "We implement this algorithm in `monte_carlo.py`. The code below will demonstrate the usage of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57bd628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline.lab.alg import monte_carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ff2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_alg = monte_carlo.MonteCarlo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "364e5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- environment is a grid world\n",
      "- x means you can't go there\n",
      "- s means start position\n",
      "- number means reward at that state\n",
      "===========\n",
      ".  .  .  1\n",
      ".  x  . -1\n",
      ".  .  .  x\n",
      "s  x  .  2\n",
      "===========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_env.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a89fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_env.random_action(gridworld_env.GridState(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e4155",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047af4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1295.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 s, sys: 385 ms, total: 8.09 s\n",
      "Wall time: 7.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "mc_alg.fit(grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c61c69",
   "metadata": {},
   "source": [
    "Let's check what value function we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4294aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 1.18| 1.31| 1.46| 1.00|\n",
      "---------------------------\n",
      " 1.31| 0.00| 1.62|-1.00|\n",
      "---------------------------\n",
      " 1.46| 1.62| 1.80| 0.00|\n",
      "---------------------------\n",
      " 1.31| 0.00| 2.00| 2.00|\n"
     ]
    }
   ],
   "source": [
    "gridworld_utils.print_values(mc_alg._state_2_value, grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7f10b",
   "metadata": {},
   "source": [
    "Then let's print the learned policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "976fb2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "  R  |  R  |  D  |  ?  |\n",
      "---------------------------\n",
      "  D  |  x  |  D  |  ?  |\n",
      "---------------------------\n",
      "  R  |  R  |  D  |  x  |\n",
      "---------------------------\n",
      "  U  |  x  |  R  |  ?  |\n"
     ]
    }
   ],
   "source": [
    "gridworld_utils.print_policy(mc_alg._policy, grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e2c13",
   "metadata": {},
   "source": [
    "#### Prior run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da574b5b",
   "metadata": {},
   "source": [
    "Finally, let's reset the environment and play the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af03368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin state=GridState(i=3, j=0)\n",
      "ActionResult(action='U', state=GridState(i=2, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=2, j=1), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=2, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='D', state=GridState(i=3, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=3, j=3), reward=2, is_done=True, is_truncated=False, info=None)\n",
      "Final reward=2 with 5 step(s)\n"
     ]
    }
   ],
   "source": [
    "# Play game util done\n",
    "grid_env.reset()\n",
    "\n",
    "print(f'Begin state={grid_env.current_state}')\n",
    "step_count = 0\n",
    "while not grid_env.is_done:\n",
    "    result = mc_alg.play(grid_env)\n",
    "    step_count += 1\n",
    "    print(result)\n",
    "print(f'Final reward={result.reward} with {step_count} step(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820956ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show learned value function\n",
    "# mc_alg._state_2_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec77577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show learned Q table\n",
    "# mc_alg._q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e2c89",
   "metadata": {},
   "source": [
    "<a id='random_method'></a>\n",
    "### <font color='darkgreen'>Random Method</font>\n",
    "This method takes random action in the given environment. It is often used as a based line to evaluate other RL methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd62d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline.lab.alg import random_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcdd775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_alg = random_rl.RandomRL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db98e07",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Random won't require any training and therefore below call should end in no time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2097d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 4 µs, total: 16 µs\n",
      "Wall time: 30.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "random_alg.fit(grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57673b4a",
   "metadata": {},
   "source": [
    "#### Prior run\n",
    "Since this is a random process, each time you play the game will have difference result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f154d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin state=GridState(i=3, j=0)\n",
      "ActionResult(action='U', state=GridState(i=2, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='D', state=GridState(i=3, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=2, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='D', state=GridState(i=3, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=2, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=1, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=0, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=1), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='D', state=GridState(i=1, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=0, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='L', state=GridState(i=0, j=1), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='L', state=GridState(i=0, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=1), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=3), reward=1, is_done=True, is_truncated=False, info=None)\n",
      "Final reward=1 with 16 step(s)\n"
     ]
    }
   ],
   "source": [
    "# Play game util done\n",
    "grid_env.reset()\n",
    "\n",
    "print(f'Begin state={grid_env.current_state}')\n",
    "step_count = 0\n",
    "while not grid_env.is_done:\n",
    "    result = random_alg.play(grid_env)\n",
    "    step_count += 1\n",
    "    print(result)\n",
    "print(f'Final reward={result.reward} with {step_count} step(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31d4e7",
   "metadata": {},
   "source": [
    "From the result above, it is obviously that <a href='#monte_carlo_method'><b>Monte Carlo Method</b></a> can perform much better than <a href='#random_method'><b>Random Method</b></a>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee12ee4",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Scoreboard</font>\n",
    "Before we know how score board work, we need to understand <b><font color='blue'>RLExaminer</font></b> first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9e02d",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>RLExaminer</font>\n",
    "Every environment can have more than one examiner to calculate the score of RL method. Each examiner may have its own aspect to evaluate the RL method (time, reward etc.). Let's check one used to calculate the average reward of grid environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0edfceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner = gridworld_env.GridWorldExaminer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c32bee",
   "metadata": {},
   "source": [
    "Then, what's score of `Monte Carlo Method`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec60250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examiner.score(mc_alg, grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c476a",
   "metadata": {},
   "source": [
    "`Monte Carlo Method` got score 0.4. Let's check another RL method `Random Method`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a3c08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examiner.score(random_alg, grid_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c41b83",
   "metadata": {},
   "source": [
    "`Random Method` got score 0.5 which is less than `Monte Carlo Method`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526f9d9",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Score Board</font>\n",
    "<b><font color='blue'>Scoreboard</font></b> literally calculate the scores of given RL methods according to the specific examiner and the rank those RL methods accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56eb658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_board = lab.Scoreboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46f80bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---------------------+\n",
      "| Rank. |  RL Name   |        Score        |\n",
      "+-------+------------+---------------------+\n",
      "|   1   | MonteCarlo |         0.4         |\n",
      "|   2   |  RandomRL  | 0.13333333333333333 |\n",
      "+-------+------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "sorted_scores  = score_board.rank(\n",
    "    examiner=examiner, env=grid_env, rl_methods=[random_alg, mc_alg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5b4af04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MonteCarlo', 0.4), ('RandomRL', 0.13333333333333333)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c461de5",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>A Real World RL problem (BCST test case selection)</font>\n",
    "Here we are going to use a real-world example to explain how this lab works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdcccf2",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Explore the environment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a48c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline.lab import bcst_tc_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c579d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcst_env = bcst_tc_env.BCSTEnvironment()\n",
    "bcst_examiner = bcst_tc_env.BCSTRewardCountExaminer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af7f7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rl_test_case3',\n",
       " 'rl_test_case5',\n",
       " 'rl_test_case2',\n",
       " 'rl_test_case4',\n",
       " 'rl_test_case1']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcst_env.available_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d93e2169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(),\n",
       " ('rl_test_case3',),\n",
       " ('rl_test_case5',),\n",
       " ('rl_test_case2',),\n",
       " ('rl_test_case4',),\n",
       " ('rl_test_case1',),\n",
       " ('rl_test_case3', 'rl_test_case3'),\n",
       " ('rl_test_case3', 'rl_test_case5'),\n",
       " ('rl_test_case3', 'rl_test_case2'),\n",
       " ('rl_test_case3', 'rl_test_case4')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcst_env.available_states()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6ea5f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rl_test_case1', 'rl_test_case2')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcst_env.step('rl_test_case1')\n",
    "bcst_env.step('rl_test_case2')\n",
    "bcst_env.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d656f170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rl_test_case2', 'rl_test_case3', 'rl_test_case4')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcst_env.step('rl_test_case3')\n",
    "bcst_env.step('rl_test_case4')\n",
    "bcst_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316f676",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Random RL</font>\n",
    "Let's check our baseline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd917d63",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93c4835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 3 µs, total: 11 µs\n",
      "Wall time: 16.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "random_alg.fit(bcst_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0eec6b",
   "metadata": {},
   "source": [
    "#### Prior run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11900d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActionResult(action='rl_test_case2', state=('rl_test_case2',), reward=0, is_done=False, is_truncated=False, info=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcst_env.reset()\n",
    "random_alg.play(bcst_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05542b2e",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23b66ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=62.00\n"
     ]
    }
   ],
   "source": [
    "score = bcst_examiner.score(random_alg, bcst_env, play_round=10)\n",
    "print(f'Score={score:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b172d",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Monte Carlo Method</font>\n",
    "Next let's check `Monte Carlo Method` with two cases. One for default option `round_num=10000`, another one with parameter `round_num=15000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee01c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_alg_r1000 = monte_carlo.MonteCarlo(name='r1000', round_num=1000)\n",
    "mc_alg_r5000 = monte_carlo.MonteCarlo(name='r5000', round_num=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49482d40",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94f7ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 189.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 357 ms, total: 5.6 s\n",
      "Wall time: 5.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training of default setting\n",
    "mc_alg_r1000.fit(bcst_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b0742f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:35<00:00, 140.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 2.51 s, total: 37.6 s\n",
      "Wall time: 35.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training of Monte Carlo Method for larger `round_num`\n",
    "mc_alg_r5000.fit(bcst_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4f2ac",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a8519b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Method (r1000) with Score=59.40\n"
     ]
    }
   ],
   "source": [
    "score = bcst_examiner.score(mc_alg_r1000, bcst_env, play_round=10)\n",
    "print(f'Monte Carlo Method ({mc_alg_r1000.name}) with Score={score:.02f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "557abd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Method (r5000) with Score=139.50\n"
     ]
    }
   ],
   "source": [
    "score = bcst_examiner.score(mc_alg_r5000, bcst_env, play_round=10)\n",
    "print(f'Monte Carlo Method ({mc_alg_r5000.name}) with Score={score:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce9ee9",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Score Board</font>\n",
    "Finally, let's check the ranking among supported RL methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ea00f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+\n",
      "| Rank. | RL Name  | Score |\n",
      "+-------+----------+-------+\n",
      "|   1   |  r5000   | 135.0 |\n",
      "|   2   |  r1000   |  58.0 |\n",
      "|   3   | RandomRL |  52.0 |\n",
      "+-------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "sorted_scores  = score_board.rank(\n",
    "    examiner=bcst_examiner, env=bcst_env,\n",
    "    rl_methods=[random_alg, mc_alg_r1000, mc_alg_r5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cf39c",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [Udemy - Artificial Intelligence: Reinforcement Learning in Python](https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
