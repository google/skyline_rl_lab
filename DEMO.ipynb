{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615fd34d",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Prefce</font>\n",
    "Here we are going to use a toy testing environment `GridWorld` to demonstrate the usage of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd68f300",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Importing Packages</font>\n",
    "Firstly, let's import all the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce17785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline import lab\n",
    "from skyline.lab import gridworld_env\n",
    "from skyline.lab import gridworld_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797ee9",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Make Lab Environment</font>\n",
    "We use function <font color='blue'>make</font> to obtain the testing environment. e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff46a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_env = lab.make(lab.Env.GridWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7b6952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U', 'D', 'L', 'R']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show available actions\n",
    "grid_env.available_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2097e787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=2, j=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1564b",
   "metadata": {},
   "source": [
    "Let's take a action and check the state change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39fdf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=1, j=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take action 'Up'\n",
    "grid_env.step('U')\n",
    "\n",
    "# Check current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6748196",
   "metadata": {},
   "source": [
    "After taking action `U`, we expect the axis-i to move up from 2->1 and we can confirm it from the output state. Let's reset the environment by calling method <font color='blue'>reset</font> which will bring the state of environment back to intial state `GridState(i=2, j=0)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718ed1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridState(i=2, j=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset environment\n",
    "grid_env.reset()\n",
    "\n",
    "# Check current state\n",
    "grid_env.current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd1109",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Experiments of RL algorithms</font>\n",
    "Here we are going to test some well-known RL algorithms and demonstrate the usage of this lab:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4293e",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Monte Carlo Method</font>\n",
    "<b><font size='3ptx'>In this method, we simply simulate many trajectories (<font color='darkbrown'>decision processes</font>), and calculate the average returns.</font></b> ([wiki page](https://en.wikiversity.org/wiki/Reinforcement_Learning#Monte_Carlo_policy_evaluation))\n",
    "\n",
    "We implement this algorithm in `monte_carlo.py`. The code below will demonstrate the usage of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bd628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyline.lab.alg import monte_carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ff2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_alg = monte_carlo.MonteCarlo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364e5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- environment is a grid world\n",
      "- x means you can't go there\n",
      "- s means start position\n",
      "- number means reward at that state\n",
      "===========\n",
      ".  .  .  1\n",
      ".  x  . -1\n",
      "s  .  .  .\n",
      "===========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_env.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a89fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_env.random_action(gridworld_env.GridState(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047af4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:03<00:00, 2812.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "mc_alg.fit(grid_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4294aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.81| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.90| 0.00|\n",
      "---------------------------\n",
      " 0.66| 0.73| 0.81| 0.72|\n"
     ]
    }
   ],
   "source": [
    "gridworld_utils.print_values(mc_alg._state_2_value, grid_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976fb2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "gridworld_utils.print_policy(mc_alg._policy, grid_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82be40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af03368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionResult(action='U', state=GridState(i=1, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='U', state=GridState(i=0, j=0), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=1), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=2), reward=0, is_done=False, is_truncated=False, info=None)\n",
      "ActionResult(action='R', state=GridState(i=0, j=3), reward=1, is_done=True, is_truncated=False, info=None)\n"
     ]
    }
   ],
   "source": [
    "# Play game util done\n",
    "while not grid_env.is_done:\n",
    "    result = mc_alg.play(grid_env)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cf39c",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [Udemy - Artificial Intelligence: Reinforcement Learning in Python](https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
